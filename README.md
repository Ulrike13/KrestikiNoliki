# KrestikiNoliki

### Задачи:
* Разработать RL-агента;
* В качестве методов RL использовать Q-learning;
* Агент ходит не однообразно;
* Добиться качественных статистических показателей игры агента:

     a) у агента невозможно выйграть;
  
     б) агент всегда ходит в пользу своей победы, сводя к максимально возможному минимуму процент ничьих.

График обучения агента против агента со стратегией рандомного хода (10000 матчей):

![Plot](https://github.com/Ulrike13/KrestikiNoliki/assets/126660175/be7fd7ab-c614-4540-8f20-f893af0485d3)

На графике видно, что в процессе обучения агента процент побед стремится к 90%, в то время как ничьи и поражений стремятся к 10% и 0%.
Это очень хорошо.

### Особенности:
В ходе игры агент автоматически создает Q-таблицу, расширяя её новыми состояниями стола, и при этом инициализирует все доступные действия для этих состояний.
